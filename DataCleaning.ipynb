{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c11b19a1",
   "metadata": {},
   "source": [
    "# E‑Commerce Business Data Cleaning & Validation\n",
    "This notebook prepares dirty, unequal, executive‑grade e‑commerce data for analysis by validating keys, fixing integrity issues, handling nulls & duplicates, standardizing values, and removing outliers using the IQR method.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- Ensure Primary Key (PK) uniqueness & validity\n",
    "\n",
    "- Validate Foreign Key (FK) relationships across tables\n",
    "\n",
    "- Handle nulls, duplicates, invalid values\n",
    "\n",
    "- Standardize inconsistent categorical data\n",
    "\n",
    "- Remove outliers using IQR (analysis‑safe)\n",
    "\n",
    "- Deliver clean, analysis‑ready datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7ce38216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38c2d21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "\n",
    "sales = pd.read_csv(\"data/sales_transactions.csv\")\n",
    "customers = pd.read_csv(\"data/customers.csv\")\n",
    "products = pd.read_csv(\"data/products.csv\")\n",
    "stores = pd.read_csv(\"data/stores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b04d67df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['KY', 'FL', 'OR', 'AL', 'PA', 'DC', 'CA', 'VI', 'NJ', 'NV', 'SD',\n",
       "       'NE', 'MI', 'WY', 'CT', 'GA', 'MN', 'IA', 'ND', 'CO', 'WI', 'LA',\n",
       "       'DE', 'HI', 'RI', 'NC', 'PR', 'ID', 'NH', 'MH', 'NM', 'NY', 'WA',\n",
       "       'AZ', 'AK', 'WV', 'AS', 'MO', 'VT', 'TX', 'GU', 'OH', 'MT', 'IN',\n",
       "       'FM', 'MP', 'IL', 'KS', 'PW', 'MS', 'SC', 'AR', 'MA', 'TN', 'ME',\n",
       "       'OK', 'VA', 'UT', 'MD'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the preview \n",
    "\"\"\"\n",
    "table = {\n",
    "    \"Sales\": sales,\n",
    "    \"Customers\": customers,\n",
    "    \"Products\": products,\n",
    "    \"Stores\": stores\n",
    "}\n",
    "for name, df in table.items():\n",
    "    print(f\"\\n{name} Shape:\", df.shape)\n",
    "    display(df.head())\"\"\"\n",
    "\n",
    "customers['State'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac28534",
   "metadata": {},
   "source": [
    "### Primary Key Uniqueness Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83f36f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Rows</th>\n",
       "      <th>Unique PKs</th>\n",
       "      <th>Duplicate PKs</th>\n",
       "      <th>Null PKs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>18150</td>\n",
       "      <td>18000</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Customers</th>\n",
       "      <td>825</td>\n",
       "      <td>800</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Products</th>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stores</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Total Rows  Unique PKs  Duplicate PKs  Null PKs\n",
       "Sales           18150       18000            150         0\n",
       "Customers         825         800             25         0\n",
       "Products          120         120              0         0\n",
       "Stores             25          25              0         0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pk_check(df, pk):\n",
    "\n",
    "    return {\n",
    "    \"Total Rows\": len(df),\n",
    "    \"Unique PKs\": df[pk].nunique(),\n",
    "    \"Duplicate PKs\": df.duplicated(pk).sum(),\n",
    "    \"Null PKs\": df[pk].isna().sum()\n",
    "}\n",
    "\n",
    "\n",
    "pk_summary = {\n",
    "\"Sales\": pk_check(sales, \"Order_ID\"),\n",
    "\"Customers\": pk_check(customers, \"Customer_ID\"),\n",
    "\"Products\": pk_check(products, \"Product_ID\"),\n",
    "\"Stores\": pk_check(stores, \"Store_ID\")\n",
    "}\n",
    "\n",
    "\n",
    "pd.DataFrame(pk_summary).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1fce3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.drop_duplicates(subset=\"Order_ID\")\n",
    "customers = customers.drop_duplicates(subset=\"Customer_ID\")\n",
    "products = products.drop_duplicates(subset=\"Product_ID\")\n",
    "stores = stores.drop_duplicates(subset=\"Store_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272d0c96",
   "metadata": {},
   "source": [
    "### Foreign Key Validation Check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4654531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales[sales[\"Customer_ID\"].isin(customers[\"Customer_ID\"])]\n",
    "sales = sales[sales[\"Product_ID\"].isin(products[\"Product_ID\"])]\n",
    "sales = sales[sales[\"Store_ID\"].isin(stores[\"Store_ID\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fade2e",
   "metadata": {},
   "source": [
    "### Null Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46633e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Order_ID           0\n",
       "Order_Date        49\n",
       "Customer_ID        0\n",
       "Product_ID         0\n",
       "Store_ID           0\n",
       "Quantity           0\n",
       "Unit_Price         0\n",
       "Discount        5558\n",
       "Revenue            0\n",
       "Cost               0\n",
       "Profit             0\n",
       "Order_Status       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f196ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = sales.dropna(subset=[\"Order_Date\", \"Customer_ID\"])\n",
    "sales[\"Discount\"] = sales[\"Discount\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae5dc87",
   "metadata": {},
   "source": [
    "### Data Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2bb10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "products[\"Category\"] = products[\"Category\"].str.lower()\n",
    "products[\"Category\"] = products[\"Category\"].replace({\n",
    "    \"electronics\": \"electronics\",\n",
    "    \"elec\": \"electronics\",\n",
    "    \"accessories\": \"accessories\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1556f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\imanc\\AppData\\Local\\Temp\\ipykernel_22076\\2319967723.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  customers[\"State\"] = customers[\"State\"].map(state_map)\n"
     ]
    }
   ],
   "source": [
    "state_map = {\n",
    "    \"AL\": \"Alabama\", \"AK\": \"Alaska\", \"AZ\": \"Arizona\", \"AR\": \"Arkansas\",\n",
    "    \"CA\": \"California\", \"CO\": \"Colorado\", \"CT\": \"Connecticut\", \"DE\": \"Delaware\",\n",
    "    \"FL\": \"Florida\", \"GA\": \"Georgia\", \"HI\": \"Hawaii\", \"ID\": \"Idaho\",\n",
    "    \"IL\": \"Illinois\", \"IN\": \"Indiana\", \"IA\": \"Iowa\", \"KS\": \"Kansas\",\n",
    "    \"KY\": \"Kentucky\", \"LA\": \"Louisiana\", \"ME\": \"Maine\", \"MD\": \"Maryland\",\n",
    "    \"MA\": \"Massachusetts\", \"MI\": \"Michigan\", \"MN\": \"Minnesota\", \"MS\": \"Mississippi\",\n",
    "    \"MO\": \"Missouri\", \"MT\": \"Montana\", \"NE\": \"Nebraska\", \"NV\": \"Nevada\",\n",
    "    \"NH\": \"New Hampshire\", \"NJ\": \"New Jersey\", \"NM\": \"New Mexico\", \"NY\": \"New York\",\n",
    "    \"NC\": \"North Carolina\", \"ND\": \"North Dakota\", \"OH\": \"Ohio\", \"OK\": \"Oklahoma\",\n",
    "    \"OR\": \"Oregon\", \"PA\": \"Pennsylvania\", \"RI\": \"Rhode Island\", \"SC\": \"South Carolina\",\n",
    "    \"SD\": \"South Dakota\", \"TN\": \"Tennessee\", \"TX\": \"Texas\", \"UT\": \"Utah\",\n",
    "    \"VT\": \"Vermont\", \"VA\": \"Virginia\", \"WA\": \"Washington\", \"WV\": \"West Virginia\",\n",
    "    \"WI\": \"Wisconsin\", \"WY\": \"Wyoming\"\n",
    "}\n",
    "\n",
    "customers[\"State\"] = customers[\"State\"].map(state_map)\n",
    "stores[\"State\"] = stores[\"State\"].map(state_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4209dd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profit is not standardize as it can be Negative\n",
    "\n",
    "numeric_cols = [\"Quantity\", \"Unit_Price\", \"Revenue\", \"Cost\"]\n",
    "\n",
    "\n",
    "for col in numeric_cols:\n",
    "    sales = sales[sales[col] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add69b91",
   "metadata": {},
   "source": [
    "### Outlier Detection and Removel (IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7406dd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower) & (df[column] <= upper)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15d21769",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"Quantity\", \"Unit_Price\", \"Revenue\", \"Profit\"]:\n",
    "    sales = remove_outliers_iqr(sales, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "781a6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[\"Order_Date\"] = pd.to_datetime(sales[\"Order_Date\"], errors=\"coerce\")\n",
    "sales = sales.dropna(subset=[\"Order_Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f662a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.to_csv(\"clean/sales.csv\", index=False)\n",
    "customers.to_csv(\"clean/customers.csv\", index=False)\n",
    "products.to_csv(\"clean/products.csv\", index=False)\n",
    "stores.to_csv(\"clean/stores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff9205a",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "\n",
    "- Referential integrity enforced\n",
    "\n",
    "- Duplicates & nulls removed\n",
    "\n",
    "- Categories standardized\n",
    "\n",
    "- Outliers handled using IQR\n",
    "\n",
    "- Analysis‑ready datasets produced"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
